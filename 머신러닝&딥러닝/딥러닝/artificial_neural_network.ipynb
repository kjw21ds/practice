{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11a2RACPVsiowLfymlvWVh_PvBoaNB1Uw","timestamp":1721197780350}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf"],"metadata":{"id":"o_8_NZg5lH2o","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":5922,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["tf.__version__   # 텐서플로 2.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"giJR32cOl3yz","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":6,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"c121c391-640a-437e-9d97-4f21757936ab"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.15.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","metadata":{"id":"MXUkhkMfU4wq","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":5,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"source":["# 고객들에게 수집한 정보를 모은 은행의 데이터 집합\n","dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[:, 3:-1].values\n","y = dataset.iloc[:, -1].values"],"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6iRIcBpm-sI","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":5,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"f44f3473-715f-4cc0-c141-544eb98e3ff7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiVzLz20m-2z","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"28f271e4-e96c-4ae4-fc24-6ce4581a8f39"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"le5MJreAbW52"},"source":["Label Encoding the \"Gender\" column"]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:, 2] = le.fit_transform(X[:, 2])"],"metadata":{"id":"jG4-y1PVnRfX","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXXj2E7ZoTGS","executionInfo":{"status":"ok","timestamp":1721212268899,"user_tz":-540,"elapsed":3,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"ea45df30-2b46-4d75-8cba-4edd7fcd2c8e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the \"Geography\" column"]},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))"],"metadata":{"id":"2KMcicYSobnA","executionInfo":{"status":"ok","timestamp":1721212268900,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCpfRgHIpFU-","executionInfo":{"status":"ok","timestamp":1721212268900,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"a17f00f8-3976-4438-aef3-33b1be1f8adc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"],"metadata":{"id":"do3x4X36puRA","executionInfo":{"status":"ok","timestamp":1721212269908,"user_tz":-540,"elapsed":1011,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","source":["# Feature Scaling은 딥러닝에서 필수. 인공신경망을 만들 때 Feature Scaling을 적용해야 함.\n","# 딥러닝에서 이 과정은 매우 중요하므로 앞에서 인코딩 작업한 feature까지 모두 스케일링 적용.\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"metadata":{"id":"zrmwCvf5qGWD","executionInfo":{"status":"ok","timestamp":1721212269908,"user_tz":-540,"elapsed":3,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","source":["# 완전 연결망으로 이루어진 딥러닝. 시퀀셜 클래스의 객체가 ann을 나타냄 .\n","# 시퀀셜 클래스는 원래 케라스 라이브러리의 models 모듈을 취함. 새로운 버전의 텐서플로 2.0이 나오면서 케라스가 텐서플로에 통합됨.\n","ann = tf.keras.models.Sequential()"],"metadata":{"id":"oo0XsVKBrZAE","executionInfo":{"status":"ok","timestamp":1721212269908,"user_tz":-540,"elapsed":3,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","source":["# Dense 클래스는 텐서플로와 파이토치에서 많이 사용. 어떤 ANN에서든 Dense 클래스로 새로운 망에 완전 연결층을 추가함\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n"," # add() 메서드로 은닉층이든 드롭아웃층이든 뭐든 원하는 것을 추가 가능. 우리가 추가하고자 하는 건 완전 연결층.\n"," # layers툴로 원하는 층 추가 가능.\n"," # Dense클래스의 매개변수 units는 뉴런 수와 정확히 일치. 가지고 싶은 히든 뉴런의 수를 지정 가능.\n"," # 몇 개의 뉴런이 있어야 할까? -> 경험적 판단은 없음. 실험을 기반으로 함.\n"," # 다양한 하이퍼파라미터로 실험을 해야 함. 무관하거나 과하지 않은 숫자를 하나 골라야 함.\n"," # 직관 강의에서 완전 연결 신경망 속 숨겨진 층들의 활성화 함수는 reLU함수여하 한다는 것을 배웠음. 따라서 activation='relu'"],"metadata":{"id":"tHObr-6YrZLs","executionInfo":{"status":"ok","timestamp":1721212269909,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","source":["# 첫번째 은닉층 추가할 때와 같은 코드 입력하면 됨. add() 메서드로 새로운 층 추가 가능.\n","# 하이퍼파라미터(초매개변수) 값을 맘대로 바꿔봐도 됨. 더 나은 정확도를 얻을 수도 있음.\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"],"metadata":{"id":"pjYMB6NOrZZ8","executionInfo":{"status":"ok","timestamp":1721212269909,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","source":["# 새로운 층을 추가하고 있고 출력층을 포함해 아무 층이나 add() 메서드로 추가 가능\n","# 그러므로 최종 출력층 추가에도 add() 메서드를 사용함.\n","# 물론 출력층이 두 번째 은닉층과 완전 연결 되어야 하기 때문에 Dense 클래스를 사용.\n","# 출력층은 출력 차원을 포함함. 자료의 출력변수는 1 또는 0이라는 이진변수를 예측하고자 함. 따라서 출력차원은 1차원\n","# 뉴런은 1개만 필요. 만약 종속변수로 3개의 클래스(A, B, C)를 가지는 분류를 한다면 3차원. 이 클래스들간에 순서는 관계 없으므로 인코딩 하면 A = 100, B = 010, C = 001\n","# 뉴런이 3개 필요함.\n","# 시그모이드 활성화 함수는 예상값을 얻는 것에서 끝나지 않고 이분형 결과가 1일 가능성도 보여줌\n","# 여기서는 해당 고객이 은행 이용을 지속할 지를 예측할 것. 더 나아가 각 고객에 대한 은행 이용 지속 가능성도 알게 됨. 이 모든 것은 시그모이드 활성화 함수로 가능\n","# 이분형이 아니라면 시그모이드가 아닌 소프트맥스를 사용.\n","ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"TXy4_KOHrZu3","executionInfo":{"status":"ok","timestamp":1721212269909,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","source":["# compile() 메서드 안에 총 3개의 매개변수 입력. optimizer, loss(손실함수), metrics <- ANN평가를 위해 동시에 여러 척도를 선택가능 하므로 복수. 우리는 accuracy만 사용.\n","# 직관 강의에서 최고의 옵티마이저는 확률적 경사 하강법이라고 배움. 확률적 경사 하강법을 수행할 수 있는 옵티마이저 = ADAM\n","# 이분화된 결과를 예측해야 한다면 손실함수가 항상 따라옴. binary_crossentropy을 입력(이분형)\n","# 이분형이 아닌 분류를 한다면 categorical_crossentropy 입력(비이분형)\n","# 회귀를 위한 ANN은 따로 동영상 링크를 줬음.\n","# metrics에 여러 개를 입력하려면 대괄호로 짝을 지어 입력(리스트 형태)\n","ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"q5gQy-bI0boo","executionInfo":{"status":"ok","timestamp":1721212269909,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","source":["ann.fit(X_train, y_train, batch_size = 32, epochs = 100) # 어떤 머신러닝 모델이건 훈련 메서드는 항상 동일\n","# ANN 훈련 시 첫번째 배치 사이즈인 매개변수 2개를 더 입력.\n","# 배치 학습은 ANN 훈련 시 항상 효율적이고 성능이 더 좋기 때문.\n","# 예측값을 실제 결과와 하나씩 비교하는 대신에 손실을 계산\n","# 배치 사이즈 매개변수는 실제 결과값과 동일한 수와 비교하여 예측값을 정확히 알려줌.\n","# 배치 사이즈 값으로는 대개 32가 선택됨.(초매개변수)\n","# 신경망은 시간이 흐르면서 정확도를 개선하기 위해 일정 에폭 수에 걸쳐 훈련을 받아야 함. 에폭 수를 100으로 설정. 너무 적은 수만 아니면 어떤 수든 가능.\n","# 신경망은 상관관계를 학습하며 일정량의 에폭을 거쳐 서 최상의 예측을 할 수 있어야 함."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5BPUhTp3C6o","executionInfo":{"status":"ok","timestamp":1721212359875,"user_tz":-540,"elapsed":89969,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"ea4c4a8c-c2b9-4c0a-f6ee-61f035130881"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 4s 8ms/step - loss: 0.5157 - accuracy: 0.7961\n","Epoch 2/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.4553 - accuracy: 0.7997\n","Epoch 3/100\n","250/250 [==============================] - 3s 11ms/step - loss: 0.4392 - accuracy: 0.8069\n","Epoch 4/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.4318 - accuracy: 0.8064\n","Epoch 5/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.4273 - accuracy: 0.8100\n","Epoch 6/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.4239 - accuracy: 0.8123\n","Epoch 7/100\n","250/250 [==============================] - 2s 10ms/step - loss: 0.4208 - accuracy: 0.8133\n","Epoch 8/100\n","250/250 [==============================] - 3s 10ms/step - loss: 0.4168 - accuracy: 0.8175\n","Epoch 9/100\n","250/250 [==============================] - 3s 13ms/step - loss: 0.4130 - accuracy: 0.8199\n","Epoch 10/100\n","250/250 [==============================] - 3s 11ms/step - loss: 0.4083 - accuracy: 0.8238\n","Epoch 11/100\n","250/250 [==============================] - 2s 8ms/step - loss: 0.4039 - accuracy: 0.8276\n","Epoch 12/100\n","250/250 [==============================] - 2s 9ms/step - loss: 0.4003 - accuracy: 0.8289\n","Epoch 13/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.3965 - accuracy: 0.8304\n","Epoch 14/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.3932 - accuracy: 0.8296\n","Epoch 15/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8315\n","Epoch 16/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.3867 - accuracy: 0.8330\n","Epoch 17/100\n","250/250 [==============================] - 2s 8ms/step - loss: 0.3843 - accuracy: 0.8330\n","Epoch 18/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.3821 - accuracy: 0.8369\n","Epoch 19/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8378\n","Epoch 20/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8395\n","Epoch 21/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8424\n","Epoch 22/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8444\n","Epoch 23/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8436\n","Epoch 24/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8469\n","Epoch 25/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8495\n","Epoch 26/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8496\n","Epoch 27/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8518\n","Epoch 28/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8531\n","Epoch 29/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8541\n","Epoch 30/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8534\n","Epoch 31/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8537\n","Epoch 32/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8546\n","Epoch 33/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8551\n","Epoch 34/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8558\n","Epoch 35/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3537 - accuracy: 0.8566\n","Epoch 36/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8559\n","Epoch 37/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8576\n","Epoch 38/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8561\n","Epoch 39/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3498 - accuracy: 0.8569\n","Epoch 40/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3495 - accuracy: 0.8569\n","Epoch 41/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8583\n","Epoch 42/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8576\n","Epoch 43/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.8580\n","Epoch 44/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8589\n","Epoch 45/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8595\n","Epoch 46/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8589\n","Epoch 47/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8572\n","Epoch 48/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8597\n","Epoch 49/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8591\n","Epoch 50/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8596\n","Epoch 51/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8610\n","Epoch 52/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8593\n","Epoch 53/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8615\n","Epoch 54/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8591\n","Epoch 55/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8589\n","Epoch 56/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8615\n","Epoch 57/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8622\n","Epoch 58/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8610\n","Epoch 59/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8611\n","Epoch 60/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8609\n","Epoch 61/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8602\n","Epoch 62/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.3396 - accuracy: 0.8619\n","Epoch 63/100\n","250/250 [==============================] - 2s 7ms/step - loss: 0.3399 - accuracy: 0.8589\n","Epoch 64/100\n","250/250 [==============================] - 2s 6ms/step - loss: 0.3396 - accuracy: 0.8602\n","Epoch 65/100\n","250/250 [==============================] - 1s 6ms/step - loss: 0.3392 - accuracy: 0.8615\n","Epoch 66/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8601\n","Epoch 67/100\n","250/250 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.8626\n","Epoch 68/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3391 - accuracy: 0.8600\n","Epoch 69/100\n","250/250 [==============================] - 1s 5ms/step - loss: 0.3395 - accuracy: 0.8599\n","Epoch 70/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3381 - accuracy: 0.8599\n","Epoch 71/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8611\n","Epoch 72/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8593\n","Epoch 73/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8622\n","Epoch 74/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8599\n","Epoch 75/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8585\n","Epoch 76/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8605\n","Epoch 77/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8597\n","Epoch 78/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8619\n","Epoch 79/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8605\n","Epoch 80/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8601\n","Epoch 81/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8604\n","Epoch 82/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8622\n","Epoch 83/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8590\n","Epoch 84/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8620\n","Epoch 85/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8605\n","Epoch 86/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8604\n","Epoch 87/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8620\n","Epoch 88/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8609\n","Epoch 89/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8633\n","Epoch 90/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8625\n","Epoch 91/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8606\n","Epoch 92/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8606\n","Epoch 93/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8635\n","Epoch 94/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8608\n","Epoch 95/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8621\n","Epoch 96/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8616\n","Epoch 97/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8630\n","Epoch 98/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8643\n","Epoch 99/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8610\n","Epoch 100/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8602\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f29d059d5d0>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# 정확도가 0.86에서 수렴. 약 20번째 에폭에서 수렴.(실행할 때마다 다름)\n","# 100번의 관측 결과 86번의 예측값이 옳았다는 것."],"metadata":{"id":"mH219Oj-5bWs","executionInfo":{"status":"ok","timestamp":1721212359875,"user_tz":-540,"elapsed":3,"user":{"displayName":"JW K","userId":"12247734576989807705"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"84QFoqGYeXHL"},"source":["### Predicting the result of a single observation"]},{"cell_type":"markdown","metadata":{"id":"CGRo3eacgDdC"},"source":["**Homework**\n","\n","Use our ANN model to predict if the customer with the following informations will leave the bank:\n","\n","Geography: France\n","\n","Credit Score: 600\n","\n","Gender: Male\n","\n","Age: 40 years old\n","\n","Tenure: 3 years\n","\n","Balance: \\$ 60000\n","\n","Number of Products: 2\n","\n","Does this customer have a credit card ? Yes\n","\n","Is this customer an Active Member: Yes\n","\n","Estimated Salary: \\$ 50000\n","\n","So, should we say goodbye to that customer ?"]},{"cell_type":"code","source":["print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n","# 1. 대괄호 쌍 안에 2차원 배열로 정보 입력. 2. 카테고리 변수에 대한 문자열 입력 대신 더미변수(가변수)값을 입력해야 함. 3. 스케일링 적용.\n","# 옵티마이저, 손실함수, matrixs로 ANN을 컴파일할 때, 시그모이드 활성화 함수를 선택했으므로\n","# 가능성의 형태로 예측값을 얻게 됨. 고객의 이용 유지 여부를 0이나 1이라는 최종 결과로 알려주는 것이 아니라\n","# 고객의 서비스 중단 가능성을 알려줌."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nuTLmS355BF","executionInfo":{"status":"ok","timestamp":1721212360341,"user_tz":-540,"elapsed":468,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"2ea8a149-16f1-48b5-b327-704305551a2a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 174ms/step\n","[[0.04222162]]\n"]}]},{"cell_type":"code","source":["# 가능성을 예측하고 싶지 않다면  > 0.5를 추가하면 이 가능성이 0.5보다 큰지 물어보기 위해 0.5를 임계값으로 선택 가능. 물론 다른 임계값을 넣어도 됨.\n","print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-7FnptQKx5k","executionInfo":{"status":"ok","timestamp":1721212360341,"user_tz":-540,"elapsed":4,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"1eed4a7e-3885-487e-ffea-01c31798d9fd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 38ms/step\n","[[False]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZhU1LTgPg-kH"},"source":["**Solution**"]},{"cell_type":"markdown","metadata":{"id":"wGjx94g2n7OV"},"source":["Therefore, our ANN model predicts that this customer stays in the bank!\n","\n","**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n","\n","**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","source":["y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5) # 이분형 예측 결과인 0 또는 1로 바꾸기 위한 작업.\n","print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cV-NSoCRL59j","executionInfo":{"status":"ok","timestamp":1721212360786,"user_tz":-540,"elapsed":448,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"f2dcb467-2f8c-4624-82c1-fed72e31720e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 0s 2ms/step\n","[[0 0]\n"," [0 1]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"o0oyfLWoaEGw"},"source":["### Making the Confusion Matrix"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNCHYqfEL6MH","executionInfo":{"status":"ok","timestamp":1721212360786,"user_tz":-540,"elapsed":2,"user":{"displayName":"JW K","userId":"12247734576989807705"}},"outputId":"efe10d18-6644-421e-f59d-355428dd533b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1507   88]\n"," [ 190  215]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.861"]},"metadata":{},"execution_count":22}]}]}